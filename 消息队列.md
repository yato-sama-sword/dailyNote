# 消息队列

## RabbitMq

## RocketMQ

### 消息队列的优势

1. **异步**
   
   常见的`Dubbo`就是适用于各个系统之间同步通信的`RPC`框架，而消息队列则实现了异步。

2. **解耦**
   
   对于一些新加入的下游功能系统（称为消费者），可能只需要上游主系统（称为生产者）所提供的生产信息（“广播信息”），通过消息队列，**生产者只需要生产消息到指定主题中，消费者只需要关注从指定主题中拉去信息**

3. **削峰**
   
   当大量请求进入系统时，也许上游系统可以处理，但下游系统无力承担，通过消息队列，**消费者只需要尽自己所能地去消息队列中取消息和消费信息**

### 消息队列的劣势

1. **可能降低系统可用性**
   
   消息队列挂了，如果要保证HA就需要搞集群，**系统复杂度up**

2. **存在重复消费信息问题/消息的顺序消费问题**
   
   发布订阅模型，主题无顺序。**可能消费者消费消息的时候没有按照生产者的发送顺序消费**

3. **存在分布式事务问题**
   
   消息队列可以进行削峰操作，**可能将消息堆积在消息队列中**

4. **存在消息堆积问题**
   
   综合参考以上问题，可用性降低，复杂度上升，**NoNoNo！！！**

### 队列模型和主题模型

1. **队列模型**
   
   生产者与消费者通过队列对应，如果存在多种消费者（多个下游系统），可以通过创建多个队列进行对应，但是违背**解耦**原则
   
   ![img](file://C:\Users\yato\Desktop\U know wt\面试准备\dailyNote\笔记.assets\16ef3834ae653469.jpg?msec=1657797480994)

2. **主题模型**
   
   该模型中，消息生产者称为**发布者**，消息消费者称为**订阅者**，存放消息的容器称为**主题**。发布者需要将法系发送到指定主题中，订阅者需要**提前订阅主题**才能接受主题的消息
   
   ![img](file://C:\Users\yato\Desktop\U know wt\面试准备\dailyNote\笔记.assets\16ef3837887d9a54sds.jpg?msec=1657797480993)

### RocektMQ消息模型

先整一张图

![img](file://C:\Users\yato\Desktop\U know wt\面试准备\dailyNote\笔记.assets\16ef383d3e8c9788.jpg?msec=1657797480997)

1. 生产者组：一般是一类生产者，一般生产相同的消息
2. 消费者组：一般是一类消费者，一般消费相同的消息
3. 主题：代表一类消息，比如订单消息、物流消息等等

每个主题中都有多个队列(分布在不同的 `Broker`中，如果是集群的话，`Broker`又分布在不同的服务器中)，集群消费模式下，一个消费者集群多台机器共同消费一个 `topic` 的多个队列，**一个队列只会被一个消费者消费**。如果某个消费者挂掉，分组内其它消费者会接替挂掉的消费者继续消费。就像上图中 `Consumer1` 和 `Consumer2` 分别对应着两个队列，而 `Consumer3` 是没有队列对应的，所以一般来讲要控制 **消费者组中的消费者个数和主题中队列个数相同**

至于为什么每个消费组都需要在队列上维护消费位置，每个主题需要维护多个队列，前者是出于记录下**消费者组的消费位移**，避免消费过的信息被再一次消费
（为支持多个消费者组消费，消息在被一个消费者组消费完后不会删除），后者则是为了提高并发能力

总结来说，`RocketMQ` 通过**使用在一个 `Topic` 中配置多个队列并且每个队列维护每个消费者组的消费位置** 实现了 **主题模式/发布订阅模式** 。

### RocketMQ架构图

大体上分为四个角色 `NameServer` 、`Broker` 、`Producer` 、`Consumer` 。

1. **Broker**主要负责消息的存储、投递和查询以及服务高可用保证，相当于消息队列服务器。（深入一点的知识是Brokewr做了集群，进行主从部署，slave定期从master同步数据。如果master宕机了，则slave提供消费服务，但是不能写入消息
2. **NameServer**主要负责**Broker管理和路由信息管理，相当于一个注册中心**。具体而言，Broker会将信息注册到NameServer中，消费者和生产者需要从NameServer中获取路由表，按照路由表信息找到对应的Broker进行通信（深入一点的知识是，NameServer也做了集群部署，并且是**去中心化**的，单个Broker和所有NameServer都保持长连接，并且每隔30秒Broker会向所有NameServer发送心跳，心跳包含自身的主题配置信息
3. **Producer**即生产者，负责消息的发布（深入一点的知识是，生产者向Broker发送信息时，需要先从NameServer获取关于Broker的路由信息，然后通过**轮询**的方法去向每个队列中生产数据以达到**负载均衡**的效果
4. **Consumer**即消费者，负责消息的消费（深入一点的知识是，消费者需要通过NameServer获取所有Broker的路由信息，并向Broker发送Pull请求来获取消息数据。此外消费者可以以**广播或集群**方式启动，广播模式下，一条消息会发送给 **同一个消费组中的所有消费者** ，集群模式下消息只会发送给一个消费者。

### RocketMQ解决消息队列存在问题

1. **解决顺序消费问题**：RocketMQ在主题上**无序**，但是在队列层面可以保证**有序**。这里分为**普通顺序和严格顺序**。普通顺序指仅仅同一个消费队列收到的消息是有序的，并且Broker重启情况下，短时间内无法保证消息顺序性。而严格顺序指消费者收到的所有消息顺序都是有序的，即使异常情况下也保证消息的顺序性。**但是，只要一个Broker宕掉了，整个集群都不能用了**。一般来说短暂无序是可以接受的，在采用普通顺序模式的前提下，由于负载均衡问题，如果我们采用轮询策略，同一语义（比方说同一订单）下的不同消息会被发送到不同队列，这时候可以采用**Hash取模法**来保证同一个订单在同一个队列中。

2. **解决重复消费问题**：根据资料显示，似乎离不开两个字**幂等**，幂等又是个啥嘞？指的是一次操作任意多次执行产生影响与一次执行相同，也就是无论执行多少次都一样，相当于只执行一次。**需要根据特定场景使用特定解决方案**，大体上分为强校验和弱校验两种，**强校验**需要消费端业务实现幂等，**弱校验**用redis记录一下id作为key，设置一下过期时间，消费前判断是否消费过也不失为一种方案

3. **解决分布式事务问题**：使用**事务消息加上事务反查机制**解决分布式事务问题。第一步是发送half消息，在事务提交之前，消费者无法看见这个消息。如何实现呢？如果一个消息是**half消息**，会**备份原消息主题**与消息消费队列，并**更改主题**为RMQ_SYS_TRANS_HALF_TOPIC。由于消费组未订阅该主题，故消费端无法消费half类型的消息，**然后RocketMQ会开启一个定时任务，从Topic为RMQ_SYS_TRANS_HALF_TOPIC中拉取消息进行消费**，根据生产者组获取一个服务提供者发送回查事务状态请求，根据事务状态来决定是提交或回滚消息。总体的架构图如下嘞：
   
   这样实现了每个系统只需要保证自己的部分事务就行

4. **解决消息堆积问题**：如果是生产者生产太快，可以限流降级啥的，如果是消费者消费太慢，就需要检查消费者是否出现一些消费错误啥的。总的来说有个很简单粗暴的解决方法是增加消费者实例（记得增加主题队列数量，毕竟一个消费者对应一个队列

### RocketMQ刷盘机制

#### 同步刷盘和异步刷盘

这里是单节点层面的

![img](file://C:\Users\yato\Desktop\U know wt\面试准备\dailyNote\笔记.assets\16ef387fba311cda.jpg?msec=1657797480994)

一般地，**异步刷盘只有在 `Broker` 意外宕机的时候会丢失部分数据**

#### 同步复制和异步复制

上面的同步刷盘和异步刷盘是在单个结点层面的，而同步复制和异步复制主要是指的 `Borker` 主从模式下，主节点返回消息给客户端的时候是否需要同步从节点。

- 同步复制： 也叫 “同步双写”，也就是说，**只有消息同步双写到主从节点上时才返回写入成功** 。
- 异步复制： **消息写入主节点之后就直接返回写入成功** 。

异步复制时在主节点宕机时可能会有**短暂的信息不一致，无法保证严格顺序**。RocketMQ中采用Dledger解决这个问题，写入消息的时候，要求**至少消息复制到半数以上的节点之后**，才给客⼾端返回写⼊成功，并且它是⽀持通过选举来动态切换主节点的。

#### 存储机制

主要有三个东东，分别是CommitLog、ConsumeQueue、IndexFile

![img](笔记.assets/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NhbXBzb25fMA==,size_16,color_FFFFFF,t_70.png)
